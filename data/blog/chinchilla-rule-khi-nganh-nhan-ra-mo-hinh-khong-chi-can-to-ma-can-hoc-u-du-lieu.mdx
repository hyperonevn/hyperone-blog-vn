---
title: 'Chinchilla Rule – Khi ngành nhận ra mô hình không chỉ cần to, mà cần học đủ dữ liệu'
date: '2022-03-29'
tags: ['AI', 'NLP', '2018']
draft: false
summary: 'Đầu 2022, cả thế giới AI đang chạy đua tăng số tham số: mô hình càng to càng được tung hô. Nhưng Dee'
---

# Chinchilla Rule – Khi ngành nhận ra mô hình không chỉ cần to, mà cần học đủ dữ liệu

Đầu 2022, cả thế giới AI đang chạy đua tăng số tham số: mô hình càng to càng được tung hô. Nhưng DeepMind bước lên sân khấu với một sự thật gây sốc: nhiều mô hình “khủng” đang… được huấn luyện sai cách. Chinchilla xuất hiện như một nhà nghiên cứu kỳ cục bước vào bữa tiệc xa hoa và nói: “Các bạn ăn quá nhiều nhưng lại quên tập thể dục.”

Chinchilla có số tham số trung bình nhưng số token để huấn luyện thì tối ưu theo một quy luật mới: **model size** và **training token budget** phải cân bằng để mô hình phát huy tối đa năng lực. DeepMind cho thấy rằng nhiều mô hình lớn trước đó thực ra **undertrained** — giống như người to xác nhưng thiếu cơ bắp, chỉ phô trương chứ không mạnh thật sự.

Câu chuyện lập tức đảo ngược cuộc đua: thay vì đổ tiền tăng tham số vô tội vạ, người ta bắt đầu tính toán cẩn trọng hơn — với cùng tài nguyên, ai huấn luyện hiệu quả hơn mới là kẻ chiến thắng. Chinchilla không chỉ là một mô hình mới; nó là lời cảnh tỉnh rằng quy mô không phải tất cả. Và từ năm 2022, AI bắt đầu học cách **trở nên thông minh hơn thay vì chỉ to hơn**.