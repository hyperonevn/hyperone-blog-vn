---
title: 'Flamingo – Khi AI học nhìn và nói về thế giới bằng một mạch suy nghĩ'
date: '2022-04-29'
tags: ['AI', 'NLP', '2018']
draft: false
summary: 'Một nhà nghiên cứu bắt đầu buổi thuyết trình bằng một bức ảnh: một chú mèo đội mũ sinh nhật, cạnh bá'
---

# Flamingo – Khi AI học nhìn và nói về thế giới bằng một mạch suy nghĩ

Một nhà nghiên cứu bắt đầu buổi thuyết trình bằng một bức ảnh: một chú mèo đội mũ sinh nhật, cạnh bánh kem. Nhưng điều đáng chú ý là khi hỏi “Chú mèo này đang làm gì?”, mô hình trả lời chính xác, rồi còn kể thêm: “Có lẽ nó đang được tổ chức sinh nhật.” Mọi người cười — và rồi im lặng, vì nhận ra AI đã bước thêm một bước gần hơn tới sự hiểu biết đa giác quan.

Flamingo của DeepMind là mô hình **vision-language few-shot** cực mạnh. Nó có thể mô tả ảnh, trả lời câu hỏi dựa trên ảnh, phân tích nội dung video — tất cả chỉ với vài ví dụ hướng dẫn. Nó không chỉ nhìn, mà còn **kể chuyện** dựa trên những gì mình thấy.

Điều khiến Flamingo đặc biệt năm 2022 là cảm giác “nó hiểu thật” — không chỉ gán nhãn kiểu máy móc. Tuy vậy, mô hình vẫn có những khoảnh khắc ngây ngô, đôi khi tưởng tượng hơi quá. Nhưng rõ ràng, trong thế giới AI, nơi hình ảnh và ngôn ngữ từng là hai đại lộ tách biệt, Flamingo đã xây cây cầu đầu tiên đủ chắc để con người mơ về trợ lý AI đa giác quan đích thực.